{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water balance checks\n",
    "This notebook calculates water balances for all six laugh tests.\n",
    "\n",
    "## Notes\n",
    "The Vanderborght case requires a special approach because its outputs are only calculated for a single very long time step. Therefore we need to calculate the balance using the initial conditions as start of the time window and this requires some additional pre-procesing.\n",
    "\n",
    "## Meta data\n",
    "\n",
    "| Data  | Value  |\n",
    "|:---|:---|\n",
    "| Model name| Structure for Unifying Multiple Modelling Alternatives (SUMMA) |\n",
    "| Model version  | See attributes in output .nc file |\n",
    "| Model reference | Clark et al. (2015a,b) |\n",
    "| Model runs by | R. Zolfaghari |\n",
    "| Notebook code by | W. Knoben, A. Bennett |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "from operator import truediv \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data locations relative to the notebook\n",
    "file_paths = {'Celia'               : '../lt1_celia1990/output/celia1990_output_timestep.nc',\n",
    "              'Miller clay'         : '../lt2_miller1998/output/millerClay_output_timestep.nc',\n",
    "              'Miller loam'         : '../lt2_miller1998/output/millerLoam_output_timestep.nc',\n",
    "              'Miller sand'         : '../lt2_miller1998/output/millerSand_output_timestep.nc',\n",
    "              'Vanderborght exp. 1' : ['../lt3_vanderborght2005/output/vanderborght2005_exp1_output_timestep.nc',\n",
    "                                       '../lt3_vanderborght2005/settingsFiles/summa_zInitialCond_vanderborght2005.nc',\n",
    "                                       '../lt3_vanderborght2005/settingsFiles/summa_zParamTrial_vanderborght2005_exp1.nc'],\n",
    "              'Vanderborght exp. 2' : ['../lt3_vanderborght2005/output/vanderborght2005_exp2_output_timestep.nc',\n",
    "                                       '../lt3_vanderborght2005/settingsFiles/summa_zInitialCond_vanderborght2005.nc',\n",
    "                                       '../lt3_vanderborght2005/settingsFiles/summa_zParamTrial_vanderborght2005_exp2.nc'],\n",
    "              'Vanderborght exp. 3' : ['../lt3_vanderborght2005/output/vanderborght2005_exp3_output_timestep.nc',\n",
    "                                       '../lt3_vanderborght2005/settingsFiles/summa_zInitialCond_vanderborght2005.nc',\n",
    "                                       '../lt3_vanderborght2005/settingsFiles/summa_zParamTrial_vanderborght2005_exp3.nc'],\n",
    "              'Wigmosta exp. 1'     : '../lt4_wigmosta1994/output/syntheticHillslope-exp1_output_timestep.nc',\n",
    "              'Wigmosta exp. 2'     : '../lt4_wigmosta1994/output/syntheticHillslope-exp2_output_timestep.nc',\n",
    "              'Colbeck exp. 1'      : '../lt5_colbeck1976/output/colbeck1976-exp1_output_timestep.nc',\n",
    "              'Colbeck exp. 2'      : '../lt5_colbeck1976/output/colbeck1976-exp2_output_timestep.nc',\n",
    "              'Colbeck exp. 3'      : '../lt5_colbeck1976/output/colbeck1976-exp3_output_timestep.nc',\n",
    "              'Mizoguchi'           : '../lt6_mizoguchi1990/output/mizoguchi1990_output_timestep.nc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection parameters\n",
    "# We can use these to remove the GRU and HRU dimensions from the output files > easier data handling\n",
    "GRU, HRU = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the water balance components on a given time step\n",
    "def calc_wb(dat,domain):\n",
    "       \n",
    "    # Make some storage variables\n",
    "    vec_liqError  = []\n",
    "    vec_state     = []\n",
    "    vec_stateDiff = []\n",
    "    \n",
    "    # Find the timestep size [s]\n",
    "    dt = round((dat['time'][1] - dat['time'][0]).values/np.timedelta64(1, 's'))\n",
    "    print('    timestep size = ' + str(dt) + ' s.')\n",
    "\n",
    "    # Intrinsic densities (needed for snow)\n",
    "    iden_liq = 1000 # [kg m-3]\n",
    "    iden_ice = 917\n",
    "    \n",
    "    # --- Water balance components soil ---\n",
    "    # Start of time loop\n",
    "    for t in range(0,len(dat['time'])-1):\n",
    "       \n",
    "        # Specify time as indices\n",
    "        S_time = t \n",
    "        E_time = t+1\n",
    "    \n",
    "        # Get the layer variables at t=t\n",
    "        S_nSoil   = dat['nSoil'].isel(time=S_time).values.astype('int')\n",
    "        S_nSnow   = dat['nSnow'].isel(time=S_time).values.astype('int')\n",
    "        S_nLayers = dat['nLayers'].isel(time=S_time).values.astype('int')\n",
    "        \n",
    "        # Do computations based on the specified domain\n",
    "        if domain == 'snow':\n",
    "            \n",
    "            # Snow layer depths\n",
    "            S_mLayerDepth = dat['mLayerDepth'].isel(time=S_time,midToto=slice(0,S_nSnow)).values # needs to start at index 0, not 1 in Python\n",
    "            \n",
    "            # Snow water at the start of t=t\n",
    "            S_mLayerVolFraqLiq = dat['mLayerVolFracLiq'].isel(time=S_time,midToto=slice(0,S_nSnow)).values\n",
    "            S_mLayerVolFraqIce = dat['mLayerVolFracIce'].isel(time=S_time,midToto=slice(0,S_nSnow)).values\n",
    "            mass0 = sum( (S_mLayerVolFraqLiq * iden_liq + S_mLayerVolFraqIce * iden_ice) * S_mLayerDepth )\n",
    "            snowBalance0 = mass0 / iden_liq\n",
    "\n",
    "            # Layer variables at t=t+1\n",
    "            E_nSoil   = dat['nSoil'].isel(time=E_time).values.astype('int')\n",
    "            E_nSnow   = dat['nSnow'].isel(time=E_time).values.astype('int')\n",
    "            E_nLayers = dat['nLayers'].isel(time=E_time).values.astype('int')\n",
    "            E_mLayerDepth = dat['mLayerDepth'].isel(time=E_time,midToto=slice(0,E_nSnow)).values # needs to start at index 0, not 1 in Python\n",
    "\n",
    "            # Rainfall flux between t=t and t=t+1\n",
    "            scalarRainfall = (dat['scalarRainfall'].isel(time=E_time).values / iden_liq) * dt # [kg m-2 s-1] / [kg m-3] * [s] = [m]\n",
    "            \n",
    "            # Snowfall flux between t=t and t=t+1\n",
    "            scalarSnowfall = (dat['scalarSnowfall'].isel(time=E_time).values / iden_ice) * dt # [kg m-2 s-1] / [kg m-3] * [s] = [m]\n",
    "            \n",
    "            # Melt flux between t=t and t=t+1\n",
    "            scalarRainPlusMelt = dat['scalarRainPlusMelt'].isel(time=E_time).values * dt # [m s-1] * [s] = [m]\n",
    "            \n",
    "            # Snow water at the end of t=t; i.e. at the start of t=t+1\n",
    "            E_mLayerVolFraqLiq = dat['mLayerVolFracLiq'].isel(time=E_time,midToto=slice(0,S_nSnow)).values\n",
    "            E_mLayerVolFraqIce = dat['mLayerVolFracIce'].isel(time=E_time,midToto=slice(0,S_nSnow)).values\n",
    "            mass1 = sum( (E_mLayerVolFraqLiq * iden_liq + E_mLayerVolFraqIce * iden_ice) * E_mLayerDepth )\n",
    "            snowBalance1 = mass1 / iden_liq\n",
    "            \n",
    "            # Water balance error\n",
    "            liqError = snowBalance1 - (snowBalance0 + scalarRainfall + scalarSnowfall - scalarRainPlusMelt)\n",
    "            \n",
    "            # Append\n",
    "            vec_liqError.append(liqError)\n",
    "            vec_state.append(snowBalance1)\n",
    "            vec_stateDiff.append(snowBalance1 - snowBalance0)\n",
    "        \n",
    "        elif domain == 'soil':\n",
    "        \n",
    "            # Soil layer depths\n",
    "            S_mLayerDepth = dat['mLayerDepth'].isel(time=S_time,midToto=slice(S_nSnow,S_nLayers)).values # needs to start at index 0, not 1 in Python\n",
    "        \n",
    "            # Soil water at the start of t=t\n",
    "            S_mLayerVolFraqLiq = dat['mLayerVolFracLiq'].isel(time=S_time,midToto=slice(S_nSnow,S_nLayers)).values\n",
    "            S_mLayerVolFraqIce = dat['mLayerVolFracIce'].isel(time=S_time,midToto=slice(S_nSnow,S_nLayers)).values\n",
    "            soilBalance0 = sum( (S_mLayerVolFraqLiq + S_mLayerVolFraqIce) * S_mLayerDepth )   \n",
    "    \n",
    "            # Layer variables at t=t+1\n",
    "            E_nSoil   = dat['nSoil'].isel(time=E_time).values.astype('int')\n",
    "            E_nSnow   = dat['nSnow'].isel(time=E_time).values.astype('int')\n",
    "            E_nLayers = dat['nLayers'].isel(time=E_time).values.astype('int')\n",
    "            E_mLayerDepth = dat['mLayerDepth'].isel(time=E_time,midToto=slice(E_nSnow,E_nLayers)).values # needs to start at index 0, not 1 in Python\n",
    "        \n",
    "            # Infiltration between t=t and t=t+1 (needs t=t+1)\n",
    "            inFlux = dat['scalarInfiltration'].isel(time=E_time).values*dt\n",
    "    \n",
    "            # Transpiration between t=t and t=t+1 (needs t=t+1)\n",
    "            tranSink = dat['mLayerTranspire'].isel(time=E_time).sum().values*dt \n",
    "    \n",
    "            # Baseflow between t=t and t=t+1 (needs t=t+1)\n",
    "            baseSink = dat['mLayerBaseflow'].isel(time=E_time).sum().values*dt\n",
    "    \n",
    "            # Soil drainage between t=t and t=t+1 (needs t=t+1)\n",
    "            drainage = dat['scalarSoilDrainage'].isel(time=E_time).values*dt\n",
    "    \n",
    "            # Compression between t=t and t=t+1 (needs t=t+1)\n",
    "            mLayerCompress = dat['mLayerCompress'].isel(time=E_time,midSoil=slice(0,E_nSoil)).values\n",
    "            compSink = sum(mLayerCompress * E_mLayerDepth)\n",
    "    \n",
    "            # Soil water at the end of t=t; i.e. at the start of t=t+1\n",
    "            E_mLayerVolFraqLiq = dat['mLayerVolFracLiq'].isel(time=E_time,midToto=slice(E_nSnow,E_nLayers)).values\n",
    "            E_mLayerVolFraqIce = dat['mLayerVolFracIce'].isel(time=E_time,midToto=slice(E_nSnow,E_nLayers)).values\n",
    "            soilBalance1 = sum( (E_mLayerVolFraqLiq + E_mLayerVolFraqIce) * E_mLayerDepth )\n",
    "    \n",
    "            # Water balance error\n",
    "            liqError = soilBalance1 - (soilBalance0 + inFlux + tranSink - drainage - baseSink - compSink)\n",
    "                \n",
    "            # Append\n",
    "            vec_liqError.append(liqError)\n",
    "            vec_state.append(soilBalance1)\n",
    "            vec_stateDiff.append(soilBalance1 - soilBalance0)\n",
    "            \n",
    "    return vec_liqError, vec_state, vec_stateDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_vanderborght(file,HRU,GRU):\n",
    "    \n",
    "    # Unpack the files for clarity\n",
    "    file_sim = file[0] # simulations\n",
    "    file_ics = file[1] # initial conditions\n",
    "    file_par = file[2] # parameters\n",
    "    \n",
    "    # load the data\n",
    "    dat = xr.open_dataset( file_sim ).isel(hru=HRU, gru=GRU).load()\n",
    "    ics = xr.open_dataset( file_ics ).isel(hru=HRU) # Has no GRU dimension\n",
    "    par = xr.open_dataset( file_par )\n",
    "    \n",
    "    # --- Update the mLayerVolFracLiq values (we know ice content is 0) ---\n",
    "    psi = ics['mLayerMatricHead'].values\n",
    "    ics['mLayerVolFracLiq'][:] = calc_volFracLiq(psi,par)\n",
    "    \n",
    "    # --- Time settings for IC file ---\n",
    "    # Find the datetime at the start of the simulation timestep\n",
    "    timeE = dat['time'].values #timestamp at the end of the simulations\n",
    "    timeD = 86400000 # [s] the Vanderborght experiments are run using a single (huge) timestep of 1000 days\n",
    "    timeS = timeE - np.timedelta64(timeD,'s') #timestamp of the start of the timestep\n",
    "    \n",
    "    # Assign a time dimension to the ICs for merging\n",
    "    icsn = ics.expand_dims(time=timeS)\n",
    "    \n",
    "    # --- Merge initial conditions and simulations ---\n",
    "    # Variables with a 'midToto' dimension\n",
    "    var = ['mLayerDepth','mLayerVolFracLiq','mLayerVolFracIce']\n",
    "    merged = xr.merge([dat[var].where(dat[var] != -9999, drop=True), \\\n",
    "                        icsn[var]])\n",
    "\n",
    "    # Variables that are not part of the initial conditions and can be merged easily\n",
    "    #var = ['nSoil','nSnow','nLayers','iLayerLiqFluxSoil','mLayerTranspire','mLayerCompress','mLayerBaseflow']\n",
    "    var = ['nSoil','nSnow','nLayers','scalarInfiltration','scalarSoilDrainage','scalarSoilBaseflow', \\\n",
    "       'mLayerBaseflow','mLayerTranspire','mLayerCompress','iLayerLiqFluxSoil']\n",
    "    for v in var:\n",
    "        merged[v] = dat[v]\n",
    "    \n",
    "    # Fill the \"nX\" variables on first time step\n",
    "    var = ['nSoil','nSnow']\n",
    "    for v in var:\n",
    "        merged[v].loc[dict(time=timeS)] = icsn[v].isel(scalarv=0).values\n",
    "    merged['nLayers'].loc[dict(time=timeS)] = merged['nSoil'].loc[dict(time=timeS)].values + \\\n",
    "                                                merged['nSnow'].loc[dict(time=timeS)]\n",
    "       \n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_volFracLiq(psi,pars):\n",
    "    # Computes the volumetric liquid water content given psi and soil hydraulic parameters theta_res, \n",
    "    # theta_sat, alpha, n, and m.\n",
    "    # See summa/build/source/engine/soil_utils.f90; line 282-300\n",
    "    \n",
    "    # Get parameter values\n",
    "    theta_sat = pars['theta_sat'].values.flatten()\n",
    "    theta_res = pars['theta_res'].values.flatten()\n",
    "    alpha     = pars['vGn_alpha'].values.flatten()\n",
    "    n         = pars['vGn_n'].values.flatten()\n",
    "    m         = 1 - 1/n\n",
    "    \n",
    "    # Compute volumetric liquid fraction\n",
    "    volFracLiq = theta_res + (theta_sat - theta_res) * (1 + (alpha * psi)**n)**(-1*m)\n",
    "       \n",
    "    # Cap volFracLiq at theta_res where appropriate\n",
    "    volFracLiq[psi >= 0] =  theta_res[psi >= 0]    \n",
    "    \n",
    "    return volFracLiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_relErrSeries(wbe,dStates,states):\n",
    "    \n",
    "    # Convert to Numpy arrays for easier indexing\n",
    "    wbe = np.array(wbe)\n",
    "    dStates = np.array(dStates)\n",
    "    states = np.array(states)\n",
    "    \n",
    "    # Calculate the relative error series\n",
    "    rn = list(map(truediv,  wbe[np.nonzero(dStates)[0]], dStates[np.nonzero(dStates)[0]])) # divide two lists element-wise\n",
    "    rrn = list(map(truediv, wbe[np.nonzero(states)[0]],   states[np.nonzero(states)[0]])) \n",
    "        \n",
    "    return rn, rrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing starts here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateRelativeMetrics = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Celia\n",
      "    timestep size = 1800.0 s.\n",
      "Working on Miller clay\n",
      "    timestep size = 900.0 s.\n",
      "Working on Miller loam\n",
      "    timestep size = 900.0 s.\n",
      "Working on Miller sand\n",
      "    timestep size = 900.0 s.\n",
      "Working on Vanderborght exp. 1\n",
      "    timestep size = 86400000.0 s.\n",
      "Working on Vanderborght exp. 2\n",
      "    timestep size = 86400000.0 s.\n",
      "Working on Vanderborght exp. 3\n",
      "    timestep size = 86400000.0 s.\n",
      "Working on Wigmosta exp. 1\n",
      "    timestep size = 3600.0 s.\n",
      "Working on Wigmosta exp. 2\n",
      "    timestep size = 3600.0 s.\n",
      "Working on Colbeck exp. 1\n",
      "    timestep size = 60.0 s.\n",
      "Working on Colbeck exp. 2\n",
      "    timestep size = 60.0 s.\n",
      "Working on Colbeck exp. 3\n",
      "    timestep size = 60.0 s.\n",
      "Working on Mizoguchi\n",
      "    timestep size = 60.0 s.\n"
     ]
    }
   ],
   "source": [
    "# Initialize some lists\n",
    "test_name   = []\n",
    "maxAbsErr   = []\n",
    "meanAbsErr  = []\n",
    "cumAbsErr   = []\n",
    "maxRelErr1  = []\n",
    "meanRelErr1 = []\n",
    "maxRelErr2  = []\n",
    "meanRelErr2 = []\n",
    "\n",
    "# Loop over the files\n",
    "for test,file in file_paths.items():\n",
    "    \n",
    "    # Progress\n",
    "    print('Working on ' + test)\n",
    "    \n",
    "    # Load the data\n",
    "    if 'Colbeck' in test:\n",
    "        dat = xr.open_dataset( file ).isel(hru=HRU).load() # Colbeck output has no GRU dimensions\n",
    "        domain = 'snow'\n",
    "    elif 'Vanderborght' in test:\n",
    "        dat = prep_vanderborght( file,HRU,GRU ) # Vanderborght needs special data prep; 'file' contains sim, initial conditions and parameters\n",
    "        domain = 'soil'\n",
    "    else: # Celia, Miller, Wigmosta, Mizoguchi\n",
    "        dat = xr.open_dataset( file ).isel(hru=HRU, gru=GRU).load() \n",
    "        domain = 'soil'\n",
    "    \n",
    "    # Get water balance values\n",
    "    wbe,states,dStates = calc_wb(dat,domain)\n",
    "\n",
    "    # Calculate metrics\n",
    "    test_name.append(test)\n",
    "    maxAbsErr.append(np.max(np.abs(wbe)))\n",
    "    meanAbsErr.append(np.mean(np.abs(wbe)))\n",
    "    cumAbsErr.append(np.sum(np.abs(wbe)))\n",
    "    \n",
    "    # Calculate the relative error metrics if requested\n",
    "    if calculateRelativeMetrics:\n",
    "        rn, rrn = calc_relErrSeries(wbe,dStates,states)\n",
    "        maxRelErr1.append(np.max(rn))\n",
    "        meanRelErr1.append(np.mean(rn))      \n",
    "        maxRelErr2.append(np.max(rrn))\n",
    "        meanRelErr2.append(np.mean(rrn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Max. abs. err. [m]</th>\n",
       "      <th>Mean abs. err. [m]</th>\n",
       "      <th>Cum. abs. err. [m]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Celia</td>\n",
       "      <td>8.187895e-16</td>\n",
       "      <td>1.902073e-16</td>\n",
       "      <td>2.263467e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Miller clay</td>\n",
       "      <td>1.424614e-06</td>\n",
       "      <td>3.792766e-08</td>\n",
       "      <td>9.026783e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miller loam</td>\n",
       "      <td>5.329071e-15</td>\n",
       "      <td>2.332401e-15</td>\n",
       "      <td>5.551115e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Miller sand</td>\n",
       "      <td>1.427400e-10</td>\n",
       "      <td>3.288711e-12</td>\n",
       "      <td>7.827132e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vanderborght exp. 1</td>\n",
       "      <td>6.149307e-09</td>\n",
       "      <td>6.149307e-09</td>\n",
       "      <td>6.149307e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Vanderborght exp. 2</td>\n",
       "      <td>9.910798e-09</td>\n",
       "      <td>9.910798e-09</td>\n",
       "      <td>9.910798e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vanderborght exp. 3</td>\n",
       "      <td>1.165677e-08</td>\n",
       "      <td>1.165677e-08</td>\n",
       "      <td>1.165677e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wigmosta exp. 1</td>\n",
       "      <td>4.725063e-05</td>\n",
       "      <td>9.416612e-06</td>\n",
       "      <td>9.473112e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wigmosta exp. 2</td>\n",
       "      <td>5.402572e-05</td>\n",
       "      <td>1.381756e-05</td>\n",
       "      <td>1.390047e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Colbeck exp. 1</td>\n",
       "      <td>1.221523e-12</td>\n",
       "      <td>1.267628e-14</td>\n",
       "      <td>7.593093e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Colbeck exp. 2</td>\n",
       "      <td>3.147482e-14</td>\n",
       "      <td>3.043383e-16</td>\n",
       "      <td>1.822986e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Colbeck exp. 3</td>\n",
       "      <td>1.720846e-15</td>\n",
       "      <td>1.580075e-16</td>\n",
       "      <td>9.464651e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mizoguchi</td>\n",
       "      <td>1.695866e-14</td>\n",
       "      <td>2.465110e-16</td>\n",
       "      <td>8.871931e-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Test  Max. abs. err. [m]  Mean abs. err. [m]  \\\n",
       "0                 Celia        8.187895e-16        1.902073e-16   \n",
       "1           Miller clay        1.424614e-06        3.792766e-08   \n",
       "2           Miller loam        5.329071e-15        2.332401e-15   \n",
       "3           Miller sand        1.427400e-10        3.288711e-12   \n",
       "4   Vanderborght exp. 1        6.149307e-09        6.149307e-09   \n",
       "5   Vanderborght exp. 2        9.910798e-09        9.910798e-09   \n",
       "6   Vanderborght exp. 3        1.165677e-08        1.165677e-08   \n",
       "7       Wigmosta exp. 1        4.725063e-05        9.416612e-06   \n",
       "8       Wigmosta exp. 2        5.402572e-05        1.381756e-05   \n",
       "9        Colbeck exp. 1        1.221523e-12        1.267628e-14   \n",
       "10       Colbeck exp. 2        3.147482e-14        3.043383e-16   \n",
       "11       Colbeck exp. 3        1.720846e-15        1.580075e-16   \n",
       "12            Mizoguchi        1.695866e-14        2.465110e-16   \n",
       "\n",
       "    Cum. abs. err. [m]  \n",
       "0         2.263467e-14  \n",
       "1         9.026783e-06  \n",
       "2         5.551115e-13  \n",
       "3         7.827132e-10  \n",
       "4         6.149307e-09  \n",
       "5         9.910798e-09  \n",
       "6         1.165677e-08  \n",
       "7         9.473112e-03  \n",
       "8         1.390047e-02  \n",
       "9         7.593093e-12  \n",
       "10        1.822986e-13  \n",
       "11        9.464651e-14  \n",
       "12        8.871931e-13  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe\n",
    "if not calculateRelativeMetrics:\n",
    "    results = pd.DataFrame( {'Test'               : test_name,\n",
    "                             'Max. abs. err. [m]' : maxAbsErr,\n",
    "                             'Mean abs. err. [m]' : meanAbsErr,\n",
    "                             'Cum. abs. err. [m]' : cumAbsErr},\n",
    "                           columns = ['Test', \\\n",
    "                                      'Max. abs. err. [m]', \\\n",
    "                                      'Mean abs. err. [m]', \\\n",
    "                                      'Cum. abs. err. [m]'])\n",
    "    \n",
    "else:\n",
    "    results = pd.DataFrame( {'Test'               : test_name,\n",
    "                             'Max. abs. err.   [m]' : maxAbsErr,\n",
    "                             'Mean abs. err.   [m]' : meanAbsErr,\n",
    "                             'Cum. abs. err.   [m]' : cumAbsErr,\n",
    "                             'Max. rel. err. 1 [-]' : maxRelErr1,\n",
    "                             'Mean rel. err. 1 [-]' : meanRelErr1,\n",
    "                             'Max. rel. err. 2 [-]' : maxRelErr2,\n",
    "                             'Mean rel. err. 2 [-]' : meanRelErr2},\n",
    "                           columns = ['Test', \\\n",
    "                                      'Max. abs. err.   [m]', \\\n",
    "                                      'Mean abs. err.   [m]', \\\n",
    "                                      'Cum. abs. err.   [m]', \\\n",
    "                                      'Max. rel. err. 1 [-]', \\\n",
    "                                      'Mean rel. err. 1 [-]', \\\n",
    "                                      'Max. rel. err. 2 [-]', \\\n",
    "                                      'Mean rel. err. 2 [-]'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geospatialTools]",
   "language": "python",
   "name": "conda-env-geospatialTools-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
