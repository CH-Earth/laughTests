{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance checks\n",
    "This notebook calculates water and energy balances  for all six laugh tests.\n",
    "\n",
    "## Expectations\n",
    "Balance errors should be small, relative to maginutes of states and fluxes.\n",
    "\n",
    "The Vanderborght case requires a special approach because its outputs are only calculated for a single time step. Therefore we need to calculate the balance using the initial conditions as start of the time window.\n",
    "\n",
    "## Meta data\n",
    "\n",
    "| Data  | Value  |\n",
    "|:---|:---|\n",
    "| Model name| Structure for Unifying Multiple Modelling Alternatives (SUMMA) |\n",
    "| Model version  | See attributes in output .nc file |\n",
    "| Model reference | Clark et al. (2015a,b) |\n",
    "| Model runs by | R. Zolfaghari |\n",
    "| Notebook code by | W. Knoben, A. Bennett |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "from pathlib import Path\n",
    "from operator import truediv \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr # note, also needs netcdf4 library installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data locations relative to the notebook\n",
    "file_paths = {'Celia'               : '../lt1_celia1990/output/celia1990_output_timestep.nc',\n",
    "              'Miller clay'         : '../lt2_miller1998/output/millerClay_output_timestep.nc',\n",
    "              'Miller loam'         : '../lt2_miller1998/output/millerLoam_output_timestep.nc',\n",
    "              'Miller sand'         : '../lt2_miller1998/output/millerSand_output_timestep.nc',\n",
    "              'Wigmosta exp = 1'    : '../lt4_wigmosta1994/output/syntheticHillslope-exp1_output_timestep.nc',\n",
    "              'Wigmosta exp = 2'    : '../lt4_wigmosta1994/output/syntheticHillslope-exp2_output_timestep.nc',\n",
    "              'Colbeck exp = 1'     : '../lt5_colbeck1976/output/colbeck1976-exp1_output_timestep.nc',\n",
    "              'Colbeck exp = 2'     : '../lt5_colbeck1976/output/colbeck1976-exp2_output_timestep.nc',\n",
    "              'Colbeck exp = 3'     : '../lt5_colbeck1976/output/colbeck1976-exp3_output_timestep.nc',\n",
    "              'Mizoguchi'           : '../lt6_mizoguchi1990/output/mizoguchi1990_output_timestep.nc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selection parameters\n",
    "# We can use these to remove the GRU and HRU dimensions from the output files > easier data handling\n",
    "GRU, HRU = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the water balance components on a given time step\n",
    "def calc_wb(dat,domain):\n",
    "    \n",
    "    # Input: xarray dataset with variables:\n",
    "    # - time \n",
    "    # - nSoil\n",
    "    # - nSnow\n",
    "    # - nLayers\n",
    "    # - mLayerDepth\n",
    "    # - mLayerVolFracLiq\n",
    "    # - mLayerVolFraqIce\n",
    "    # - iLayerLiqFluxSoil\n",
    "    # - mLayerTranspire\n",
    "    # - mLayerBaseflow\n",
    "    # - mLayerCompress\n",
    "    \n",
    "    # Make some storage variables\n",
    "    vec_liqError  = []\n",
    "    vec_state     = []\n",
    "    vec_stateDiff = []\n",
    "    \n",
    "    # Find the timestep size [s]\n",
    "    dt = round((dat['time'][1] - dat['time'][0]).values/np.timedelta64(1, 's'))\n",
    "    print('    timestep size = ' + str(dt) + ' s.')\n",
    "\n",
    "    # Intrinsic densities (needed for snow)\n",
    "    iden_liq = 1000 # [kg m-3]\n",
    "    iden_ice = 917\n",
    "    \n",
    "    # --- Water balance components soil ---\n",
    "    # Start of time loop\n",
    "    for t in range(0,len(dat['time'])-1):\n",
    "       \n",
    "        # Specify time as indices\n",
    "        S_time = t \n",
    "        E_time = t+1\n",
    "    \n",
    "        # Get the layer variables at t=t\n",
    "        S_nSoil   = dat['nSoil'].isel(time=S_time).values.astype('int')\n",
    "        S_nSnow   = dat['nSnow'].isel(time=S_time).values.astype('int')\n",
    "        S_nLayers = dat['nLayers'].isel(time=S_time).values.astype('int')\n",
    "        \n",
    "        # Do computations based on the specified domain\n",
    "        if domain == 'snow':\n",
    "            \n",
    "            # Snow layer depths\n",
    "            S_mLayerDepth = dat['mLayerDepth'].isel(time=S_time,midToto=slice(0,S_nSnow)).values # needs to start at index 0, not 1 in Python\n",
    "            \n",
    "            # Snow water at the start of t=t\n",
    "            S_mLayerVolFraqLiq = dat['mLayerVolFracLiq'].isel(time=S_time,midToto=slice(0,S_nSnow)).values\n",
    "            S_mLayerVolFraqIce = dat['mLayerVolFracIce'].isel(time=S_time,midToto=slice(0,S_nSnow)).values\n",
    "            mass0 = sum( (S_mLayerVolFraqLiq * iden_liq + S_mLayerVolFraqIce * iden_ice) * S_mLayerDepth )\n",
    "            snowBalance0 = mass0 / iden_liq\n",
    "\n",
    "            # Layer variables at t=t+1\n",
    "            E_nSoil   = dat['nSoil'].isel(time=E_time).values.astype('int')\n",
    "            E_nSnow   = dat['nSnow'].isel(time=E_time).values.astype('int')\n",
    "            E_nLayers = dat['nLayers'].isel(time=E_time).values.astype('int')\n",
    "            E_mLayerDepth = dat['mLayerDepth'].isel(time=E_time,midToto=slice(0,E_nSnow)).values # needs to start at index 0, not 1 in Python\n",
    "\n",
    "            # Rainfall flux between t=t and t=t+1\n",
    "            scalarRainfall = (dat['scalarRainfall'].isel(time=E_time).values / iden_liq) * dt # [kg m-2 s-1] / [kg m-3] * [s] = [m]\n",
    "            \n",
    "            # Snowfall flux between t=t and t=t+1\n",
    "            scalarSnowfall = (dat['scalarSnowfall'].isel(time=E_time).values / iden_ice) * dt # [kg m-2 s-1] / [kg m-3] * [s] = [m]\n",
    "            \n",
    "            # Melt flux between t=t and t=t+1\n",
    "            scalarRainPlusMelt = dat['scalarRainPlusMelt'].isel(time=E_time).values * dt # [m s-1] * [s] = [m]\n",
    "            \n",
    "            # Snow water at the end of t=t; i.e. at the start of t=t+1\n",
    "            E_mLayerVolFraqLiq = dat['mLayerVolFracLiq'].isel(time=E_time,midToto=slice(0,S_nSnow)).values\n",
    "            E_mLayerVolFraqIce = dat['mLayerVolFracIce'].isel(time=E_time,midToto=slice(0,S_nSnow)).values\n",
    "            mass1 = sum( (E_mLayerVolFraqLiq * iden_liq + E_mLayerVolFraqIce * iden_ice) * E_mLayerDepth )\n",
    "            snowBalance1 = mass1 / iden_liq\n",
    "            \n",
    "            # Water balance error\n",
    "            liqError = snowBalance1 - (snowBalance0 + scalarRainfall + scalarSnowfall - scalarRainPlusMelt)\n",
    "            \n",
    "            # Append\n",
    "            vec_liqError.append(liqError)\n",
    "            vec_state.append(snowBalance1)\n",
    "            vec_stateDiff.append(snowBalance1 - snowBalance0)\n",
    "        \n",
    "        elif domain == 'soil':\n",
    "        \n",
    "            # Soil layer depths\n",
    "            S_mLayerDepth = dat['mLayerDepth'].isel(time=S_time,midToto=slice(S_nSnow,S_nLayers)).values # needs to start at index 0, not 1 in Python\n",
    "        \n",
    "            # Soil water at the start of t=t\n",
    "            S_mLayerVolFraqLiq = dat['mLayerVolFracLiq'].isel(time=S_time,midToto=slice(S_nSnow,S_nLayers)).values\n",
    "            S_mLayerVolFraqIce = dat['mLayerVolFracIce'].isel(time=S_time,midToto=slice(S_nSnow,S_nLayers)).values\n",
    "            soilBalance0 = sum( (S_mLayerVolFraqLiq + S_mLayerVolFraqIce) * S_mLayerDepth )   \n",
    "    \n",
    "            # Layer variables at t=t+1\n",
    "            E_nSoil   = dat['nSoil'].isel(time=E_time).values.astype('int')\n",
    "            E_nSnow   = dat['nSnow'].isel(time=E_time).values.astype('int')\n",
    "            E_nLayers = dat['nLayers'].isel(time=E_time).values.astype('int')\n",
    "            E_mLayerDepth = dat['mLayerDepth'].isel(time=E_time,midToto=slice(E_nSnow,E_nLayers)).values # needs to start at index 0, not 1 in Python\n",
    "        \n",
    "            # Vertical downward flux between t=t and t=t+1 (needs t=t+1)\n",
    "            iLayerLiqFluxSoil_top = dat['iLayerLiqFluxSoil'].isel(time=E_time,ifcSoil=E_nSoil).values\n",
    "            iLayerLiqFluxSoil_bot = dat['iLayerLiqFluxSoil'].isel(time=E_time,ifcSoil=0).values\n",
    "            vertFlux = -1* (iLayerLiqFluxSoil_top - iLayerLiqFluxSoil_bot) * dt\n",
    "    \n",
    "            # Transpiration between t=t and t=t+1 (needs t=t+1)\n",
    "            tranSink = dat['mLayerTranspire'].isel(time=E_time).sum().values*dt \n",
    "    \n",
    "            # Baseflow between t=t and t=t+1 (needs t=t+1)\n",
    "            baseSink = dat['mLayerBaseflow'].isel(time=E_time).sum().values*dt\n",
    "    \n",
    "            # Compression between t=t and t=t+1 (needs t=t+1)\n",
    "            mLayerCompress = dat['mLayerCompress'].isel(time=E_time,midSoil=slice(0,E_nSoil)).values\n",
    "            compSink = sum(mLayerCompress * E_mLayerDepth)\n",
    "    \n",
    "            # Soil water at the end of t=t; i.e. at the start of t=t+1\n",
    "            E_mLayerVolFraqLiq = dat['mLayerVolFracLiq'].isel(time=E_time,midToto=slice(E_nSnow,E_nLayers)).values\n",
    "            E_mLayerVolFraqIce = dat['mLayerVolFracIce'].isel(time=E_time,midToto=slice(E_nSnow,E_nLayers)).values\n",
    "            soilBalance1 = sum( (E_mLayerVolFraqLiq + E_mLayerVolFraqIce) * E_mLayerDepth )\n",
    "    \n",
    "            # Water balance error\n",
    "            liqError = soilBalance1 - (soilBalance0 + vertFlux + tranSink - baseSink - compSink)\n",
    "        \n",
    "            # Append\n",
    "            vec_liqError.append(liqError)\n",
    "            vec_state.append(soilBalance1)\n",
    "            vec_stateDiff.append(soilBalance1 - soilBalance0)\n",
    "            \n",
    "    return vec_liqError, vec_state, vec_stateDiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Working on Celia\n",
      "    timestep size = 1800.0 s.\n",
      "Working on Miller clay\n",
      "    timestep size = 900.0 s.\n",
      "Working on Miller loam\n",
      "    timestep size = 900.0 s.\n",
      "Working on Miller sand\n",
      "    timestep size = 900.0 s.\n",
      "Working on Wigmosta exp = 1\n",
      "    timestep size = 3600.0 s.\n",
      "Working on Wigmosta exp = 2\n",
      "    timestep size = 3600.0 s.\n",
      "Working on Colbeck exp = 1\n",
      "    timestep size = 60.0 s.\n",
      "Working on Colbeck exp = 2\n",
      "    timestep size = 60.0 s.\n",
      "Working on Colbeck exp = 3\n",
      "    timestep size = 60.0 s.\n",
      "Working on Mizoguchi\n",
      "    timestep size = 60.0 s.\n"
     ]
    }
   ],
   "source": [
    "# initiate some lists\n",
    "test_name   = []\n",
    "maxAbsErr   = []\n",
    "meanAbsErr  = []\n",
    "cumAbsErr   = []\n",
    "maxRelErr1  = []\n",
    "meanRelErr1 = []\n",
    "maxRelErr2  = []\n",
    "meanRelErr2 = []\n",
    "\n",
    "# loop over the files\n",
    "for test,file in file_paths.items():\n",
    "    \n",
    "    # progress\n",
    "    print('Working on ' + test)\n",
    "    \n",
    "    # load the data\n",
    "    if 'Colbeck' in test:\n",
    "        dat = xr.open_dataset( file ).isel(hru=HRU).load() # Colbeck output has no GRU dimensions\n",
    "        domain = 'snow'\n",
    "    else:\n",
    "        dat = xr.open_dataset( file ).isel(hru=HRU, gru=GRU).load()\n",
    "        domain = 'soil'\n",
    "    \n",
    "    # Get water balance values\n",
    "    wbe,states,dStates = calc_wb(dat,domain)\n",
    "\n",
    "    # Calculate the relative error series\n",
    "    rn = list(map(truediv, wbe, dStates))\n",
    "    rrn = list(map(truediv, wbe, states)) # divide two lists element-wise\n",
    "              \n",
    "    # Remove NaNs if present\n",
    "    rn  = [np.abs(val) for val in rn if str(val) != 'nan']\n",
    "    rrn = [np.abs(val) for val in rrn if str(val) != 'nan']\n",
    "        \n",
    "    # Store the remaining metrics\n",
    "    test_name.append(test)\n",
    "    maxAbsErr.append(np.max(np.abs(wbe)))\n",
    "    meanAbsErr.append(np.mean(np.abs(wbe)))\n",
    "    cumAbsErr.append(np.sum(np.abs(wbe)))\n",
    "    maxRelErr1.append(np.max(rn))\n",
    "    meanRelErr1.append(np.mean(rn))      \n",
    "    maxRelErr2.append(np.max(np.abs(rrn)))\n",
    "    meanRelErr2.append(np.mean(np.abs(rrn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               Test  Max abs err    [m]  Mean abs err   [m]  \\\n",
       "0             Celia        2.775558e-16        6.122553e-17   \n",
       "1       Miller clay        1.185140e-06        1.008642e-07   \n",
       "2       Miller loam        1.065814e-14        1.153139e-15   \n",
       "3       Miller sand        1.130163e-11        3.546724e-13   \n",
       "4  Wigmosta exp = 1        2.164935e-15        8.619127e-17   \n",
       "5  Wigmosta exp = 2        4.607426e-15        1.127329e-16   \n",
       "6   Colbeck exp = 1        4.218847e-15        4.406603e-16   \n",
       "7   Colbeck exp = 2        3.330669e-15        2.423400e-16   \n",
       "8   Colbeck exp = 3        9.436896e-16        1.252940e-16   \n",
       "9         Mizoguchi        1.887379e-14        2.442013e-16   \n",
       "\n",
       "   Cumm abs err   [m]  Max rel err 1  [-]  Mean rel err 1 [-]  \\\n",
       "0        7.285839e-15        7.250664e-13        1.344705e-13   \n",
       "1        2.400569e-05        5.687777e-04        1.618044e-04   \n",
       "2        2.744471e-13        3.564724e-12        3.986814e-13   \n",
       "3        8.441203e-11        5.537628e-09        1.957501e-10   \n",
       "4        8.670842e-14        2.708387e-08        2.373592e-10   \n",
       "5        1.134093e-13        1.060408e-09        1.320544e-11   \n",
       "6        2.639555e-13        1.163348e-09        7.926049e-11   \n",
       "7        1.451617e-13        2.983476e-09        7.184128e-11   \n",
       "8        7.505108e-14        1.000000e+00        1.808696e-01   \n",
       "9        8.788803e-13                 inf                 inf   \n",
       "\n",
       "   Max rel err 2  [-]  Mean rel err 2 [-]  \n",
       "0        2.086111e-15        5.118475e-16  \n",
       "1        1.725209e-06        1.378866e-07  \n",
       "2        8.574017e-15        8.254109e-16  \n",
       "3        3.882366e-12        1.546115e-13  \n",
       "4        1.121408e-14        4.504647e-16  \n",
       "5        1.844403e-14        4.761700e-16  \n",
       "6        1.293560e-14        1.381681e-15  \n",
       "7        8.893514e-15        6.595538e-16  \n",
       "8        2.353089e-15        3.188003e-16  \n",
       "9        2.859665e-13        3.700019e-15  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Test</th>\n      <th>Max abs err    [m]</th>\n      <th>Mean abs err   [m]</th>\n      <th>Cumm abs err   [m]</th>\n      <th>Max rel err 1  [-]</th>\n      <th>Mean rel err 1 [-]</th>\n      <th>Max rel err 2  [-]</th>\n      <th>Mean rel err 2 [-]</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Celia</td>\n      <td>2.775558e-16</td>\n      <td>6.122553e-17</td>\n      <td>7.285839e-15</td>\n      <td>7.250664e-13</td>\n      <td>1.344705e-13</td>\n      <td>2.086111e-15</td>\n      <td>5.118475e-16</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Miller clay</td>\n      <td>1.185140e-06</td>\n      <td>1.008642e-07</td>\n      <td>2.400569e-05</td>\n      <td>5.687777e-04</td>\n      <td>1.618044e-04</td>\n      <td>1.725209e-06</td>\n      <td>1.378866e-07</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Miller loam</td>\n      <td>1.065814e-14</td>\n      <td>1.153139e-15</td>\n      <td>2.744471e-13</td>\n      <td>3.564724e-12</td>\n      <td>3.986814e-13</td>\n      <td>8.574017e-15</td>\n      <td>8.254109e-16</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Miller sand</td>\n      <td>1.130163e-11</td>\n      <td>3.546724e-13</td>\n      <td>8.441203e-11</td>\n      <td>5.537628e-09</td>\n      <td>1.957501e-10</td>\n      <td>3.882366e-12</td>\n      <td>1.546115e-13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wigmosta exp = 1</td>\n      <td>2.164935e-15</td>\n      <td>8.619127e-17</td>\n      <td>8.670842e-14</td>\n      <td>2.708387e-08</td>\n      <td>2.373592e-10</td>\n      <td>1.121408e-14</td>\n      <td>4.504647e-16</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Wigmosta exp = 2</td>\n      <td>4.607426e-15</td>\n      <td>1.127329e-16</td>\n      <td>1.134093e-13</td>\n      <td>1.060408e-09</td>\n      <td>1.320544e-11</td>\n      <td>1.844403e-14</td>\n      <td>4.761700e-16</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Colbeck exp = 1</td>\n      <td>4.218847e-15</td>\n      <td>4.406603e-16</td>\n      <td>2.639555e-13</td>\n      <td>1.163348e-09</td>\n      <td>7.926049e-11</td>\n      <td>1.293560e-14</td>\n      <td>1.381681e-15</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Colbeck exp = 2</td>\n      <td>3.330669e-15</td>\n      <td>2.423400e-16</td>\n      <td>1.451617e-13</td>\n      <td>2.983476e-09</td>\n      <td>7.184128e-11</td>\n      <td>8.893514e-15</td>\n      <td>6.595538e-16</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Colbeck exp = 3</td>\n      <td>9.436896e-16</td>\n      <td>1.252940e-16</td>\n      <td>7.505108e-14</td>\n      <td>1.000000e+00</td>\n      <td>1.808696e-01</td>\n      <td>2.353089e-15</td>\n      <td>3.188003e-16</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Mizoguchi</td>\n      <td>1.887379e-14</td>\n      <td>2.442013e-16</td>\n      <td>8.788803e-13</td>\n      <td>inf</td>\n      <td>inf</td>\n      <td>2.859665e-13</td>\n      <td>3.700019e-15</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Make a dataframe\n",
    "results = pd.DataFrame( {'Test'               : test_name,\n",
    "                         'Max abs err    [m]' : maxAbsErr,\n",
    "                         'Mean abs err   [m]' : meanAbsErr,\n",
    "                         'Cumm abs err   [m]' : cumAbsErr,\n",
    "                         'Max rel err 1  [-]' : maxRelErr1,\n",
    "                         'Mean rel err 1 [-]' : meanRelErr1,\n",
    "                         'Max rel err 2  [-]' : maxRelErr2,\n",
    "                         'Mean rel err 2 [-]' : meanRelErr2},\n",
    "                       columns = ['Test', 'Max abs err    [m]', 'Mean abs err   [m]', 'Cumm abs err   [m]', \\\n",
    "                                  'Max rel err 1  [-]', 'Mean rel err 1 [-]', 'Max rel err 2  [-]', \\\n",
    "                                  'Mean rel err 2 [-]'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = 'Vanderborght exp = 1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '../lt3_vanderborght2005/output/vanderborght2005_exp1_output_timestep.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'../lt3_vanderborght2005/output/vanderborght2005_exp1_output_timestep.nc'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = xr.open_dataset( file ).isel(hru=HRU, gru=GRU).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'/home/stiff/plot_laughTest/lt3_vanderborght2005/initialConditions/summa_zInitialCond_vanderborght2005.nc'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3e6ae9401127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get ICs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'Vanderborght'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mICs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'../lt3_vanderborght2005/initialConditions/summa_zInitialCond_vanderborght2005.nc'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhru\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHRU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/xarray/backends/api.py\u001b[0m in \u001b[0;36mopen_dataset\u001b[0;34m(filename_or_obj, group, decode_cf, mask_and_scale, decode_times, autoclose, concat_characters, decode_coords, engine, chunks, lock, cache, drop_variables)\u001b[0m\n\u001b[1;32m    297\u001b[0m             store = backends.NetCDF4DataStore.open(filename_or_obj,\n\u001b[1;32m    298\u001b[0m                                                    \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                                                    autoclose=autoclose)\n\u001b[0m\u001b[1;32m    300\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'scipy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             store = backends.ScipyDataStore(filename_or_obj,\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, filename, mode, format, group, writer, clobber, diskless, persist, autoclose, lock)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                    \u001b[0mdiskless\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiskless\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpersist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpersist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                                    format=format)\n\u001b[0;32m--> 280\u001b[0;31m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         return cls(ds, mode=mode, writer=writer, opener=opener,\n\u001b[1;32m    282\u001b[0m                    autoclose=autoclose, lock=lock)\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/xarray/backends/netCDF4_.py\u001b[0m in \u001b[0;36m_open_netcdf4_group\u001b[0;34m(filename, mode, group, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnetCDF4\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnc4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mclose_on_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'/home/stiff/plot_laughTest/lt3_vanderborght2005/initialConditions/summa_zInitialCond_vanderborght2005.nc'"
     ]
    }
   ],
   "source": [
    "# Get ICs\n",
    "if 'Vanderborght' in test:\n",
    "    ICs = xr.open_dataset( '../lt3_vanderborght2005/initialConditions/summa_zInitialCond_vanderborght2005.nc' ).isel(hru=HRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datetime to assign to initial conditions\n",
    "timeD = int( ICs['dt_init'].values[0] ) #np.int32 to int\n",
    "timeE = dat['time'].values\n",
    "timeS = timeE - np.timedelta64(timeD,'m')\n",
    "timeS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a time dimension to the IC file\n",
    "ICsn = ICs.expand_dims(time=timeS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "    \n",
    "# Variables with a 'midToto' dimension\n",
    "var = ['mLayerDepth','mLayerVolFracLiq','mLayerVolFracIce']\n",
    "vdb = xr.merge([dat[var].where(dat[var] != -9999, drop=True), \\\n",
    "                ICsn[var]])\n",
    "\n",
    "# Variables that are not part of the initial conditions and can be merged easily\n",
    "var = ['nSoil','nSnow','nLayers','iLayerLiqFluxSoil','mLayerTranspire','mLayerCompress','mLayerBaseflow']\n",
    "for v in var:\n",
    "    vdb[v] = dat[v]\n",
    "    \n",
    "# Fill the 'nLayers' variable on first time step\n",
    "var = ['nSoil','nSnow']\n",
    "for v in var:\n",
    "    vdb[v].loc[dict(time=timeS)] = ICsn[v].isel(scalarv=0).values\n",
    "vdb['nLayers'].loc[dict(time=timeS)] = vdb['nSoil'].loc[dict(time=timeS)].values + \\\n",
    "                                        vdb['nSnow'].loc[dict(time=timeS)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = calc_wb(vdb,'soil')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}